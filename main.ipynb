{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils.utils import *\n",
    "from utils.random_search import grid_choices_random\n",
    "from utils.grid_search import grid_choices, get_num_grid_choices\n",
    "from run_agent_parallel import train_PPO, test_rule_based, test_PPO\n",
    "import sys\n",
    "import os\n",
    "from data_collector import DataCollector, POSSIBLE_DATA\n",
    "\n",
    "\n",
    "def run_grid_search(verbose, num_repeat_experiment, df_path=None, overwrite=True, data_to_collect=POSSIBLE_DATA,\n",
    "                    MVP_key='waitingTime', save_model=True):\n",
    "    grid = load_constants('constants/constants-grid.json')\n",
    "\n",
    "    # Make the grid choice generator\n",
    "    bases, num_choices = get_num_grid_choices(grid)\n",
    "    grid_choice_gen = grid_choices(grid, bases)\n",
    "    for diff_experiment, constants in enumerate(grid_choice_gen):\n",
    "        data_collector_obj = DataCollector(data_to_collect, MVP_key, constants,\n",
    "                                           'test' if constants['agent']['agent_type'] == 'rule' else 'eval',\n",
    "                                           df_path, overwrite if diff_experiment == 0 else False, verbose)\n",
    "\n",
    "        for same_experiment in range(num_repeat_experiment):\n",
    "            print(' --- Running experiment {}.{} / {}.{} --- '.format(diff_experiment+1, same_experiment+1,\n",
    "                                                                      num_choices, num_repeat_experiment))\n",
    "            if save_model: data_collector_obj.set_save_model_path(\n",
    "                'models/saved_models/grid_{}-{}.pt'.format(diff_experiment + 1, same_experiment + 1))\n",
    "            run_experiment(diff_experiment+1, same_experiment+1, constants, data_collector_obj)\n",
    "\n",
    "\n",
    "def run_random_search(verbose, num_diff_experiments, num_repeat_experiment, allow_duplicates=False, df_path=None,\n",
    "                      overwrite=True, data_to_collect=POSSIBLE_DATA, MVP_key='waitingTime', save_model=True):\n",
    "    grid = load_constants('constants/constants-grid.json')\n",
    "\n",
    "    if not allow_duplicates:\n",
    "        _, num_choices = get_num_grid_choices(grid)\n",
    "        num_diff_experiments = min(num_choices, num_diff_experiments)\n",
    "    # Make grid choice generator\n",
    "    grid_choice_gen = grid_choices_random(grid, num_diff_experiments)\n",
    "    for diff_experiment, constants in enumerate(grid_choice_gen):\n",
    "        data_collector_obj = DataCollector(data_to_collect, MVP_key, constants,\n",
    "                                           'test' if constants['agent']['agent_type'] == 'rule' else 'eval',\n",
    "                                           df_path, overwrite if diff_experiment == 0 else False, verbose)\n",
    "\n",
    "        for same_experiment in range(num_repeat_experiment):\n",
    "            print(' --- Running experiment {}.{} / {}.{} --- '.format(diff_experiment+1, same_experiment+1,\n",
    "                                                                      num_diff_experiments, num_repeat_experiment))\n",
    "            if save_model: data_collector_obj.set_save_model_path('models/saved_models/random_{}-{}.pt'.\n",
    "                                                                  format(diff_experiment+1, same_experiment+1))\n",
    "            run_experiment(diff_experiment+1, same_experiment+1, constants, data_collector_obj)\n",
    "\n",
    "\n",
    "def run_normal(verbose, num_experiments=1, df_path=None, overwrite=True, data_to_collect=POSSIBLE_DATA,\n",
    "               MVP_key='waitingTime', save_model=True, load_model_file=None):\n",
    "    # if loading, then dont save\n",
    "    if load_model_file:\n",
    "        save_model = False\n",
    "\n",
    "    if not df_path:\n",
    "        df_path = 'run-data.xlsx'  # def. path\n",
    "\n",
    "    # Load constants\n",
    "    constants = load_constants('constants/constants.json')\n",
    "    data_collector_obj = DataCollector(data_to_collect, MVP_key, constants,\n",
    "                                       'test' if constants['agent']['agent_type'] == 'rule' or load_model_file else 'eval',\n",
    "                                       df_path, overwrite, verbose)\n",
    "\n",
    "    loaded_model = None\n",
    "    if load_model_file:\n",
    "        loaded_model = torch.load('models/saved_models/' + load_model_file)\n",
    "\n",
    "    for exp in range(num_experiments):\n",
    "        print(' --- Running experiment {} / {} --- '.format(exp + 1, num_experiments))\n",
    "        if save_model: data_collector_obj.set_save_model_path('models/saved_models/normal_{}.pt'.format(exp+1))\n",
    "        run_experiment(exp+1, None, constants, data_collector_obj, loaded_model=loaded_model)\n",
    "\n",
    "\n",
    "def run_experiment(exp1, exp2, constants, data_collector_obj, loaded_model=None):\n",
    "    data_collector_obj.start_timer()\n",
    "\n",
    "    if loaded_model:\n",
    "        test_PPO(constants, device, data_collector_obj, loaded_model)\n",
    "    elif constants['agent']['agent_type'] == 'ppo':\n",
    "        train_PPO(constants, device, data_collector_obj)\n",
    "    else:\n",
    "        assert constants['agent']['agent_type'] == 'rule'\n",
    "        test_rule_based(constants, device, data_collector_obj)\n",
    "\n",
    "    # Save and Refresh the data_collector\n",
    "    data_collector_obj.end_timer(printIt=True)\n",
    "    data_collector_obj.process_data()\n",
    "    data_collector_obj.print_summary(exp1, exp2)\n",
    "    data_collector_obj.done_with_experiment()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # we need to import python modules from the $SUMO_HOME/tools directory\n",
    "    if 'SUMO_HOME' in os.environ:\n",
    "        tools = os.path.join(os.environ['SUMO_HOME'], 'tools')\n",
    "        sys.path.append(tools)\n",
    "    else:\n",
    "        sys.exit(\"please declare environment variable 'SUMO_HOME'\")\n",
    "\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    # df_path = 'run-data.xlsx'\n",
    "\n",
    "    # print('Num cores: {}'.format(mp.cpu_count()))\n",
    "\n",
    "    run_normal(verbose=False, num_experiments=3, df_path='run-data.xlsx', overwrite=True,\n",
    "               data_to_collect=POSSIBLE_DATA, MVP_key='waitingTime', save_model=True, load_model_file=None)\n",
    "\n",
    "    # run_random_search(verbose=False, num_diff_experiments=800, num_repeat_experiment=3, allow_duplicates=False,\n",
    "    #                   df_path='run-data.xlsx', overwrite=True, data_to_collect=POSSIBLE_DATA, MVP_key='waitingTime',\n",
    "    #                   save_model=True)\n",
    "\n",
    "    # run_grid_search(verbose=False, num_repeat_experiment=3, df_path='run-data.xlsx', overwrite=True,\n",
    "    #                 data_to_collect=POSSIBLE_DATA, MVP_key='waitingTime', save_model=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
